'use client'

import { useEffect, useRef, useState } from 'react'
import { Button } from '@/components/ui/button'
import { Play, Pause, Upload } from 'lucide-react'

// ============================================================================
// ğŸ¨ ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®èª¿æ•´ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
// ============================================================================
// ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã—ã¦ã€KENWOOD D919ã®UIã‚’å†ç¾ã—ã¦ãã ã•ã„

const SPECTRUM_CONFIG = {
  // ãƒãƒ³ãƒ‰è¨­å®š
  numBands: 17,              // ãƒãƒ³ãƒ‰ã®æ•°ï¼ˆå‘¨æ³¢æ•°å¸¯åŸŸã®æ•°ï¼‰
  segmentsPerBand: 26,       // å„ãƒãƒ³ãƒ‰ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°ï¼ˆç¸¦æ–¹å‘ã®ãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
  levelsPerBand: 13,         // éŸ³é‡ãƒ¬ãƒ™ãƒ«ã®æ®µéšæ•°ï¼ˆ2ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§1ãƒ¬ãƒ™ãƒ«ï¼‰
  
  // ãƒ–ãƒ­ãƒƒã‚¯ã®å¯¸æ³•
  blockWidth: 24.5,          // å„ãƒ–ãƒ­ãƒƒã‚¯ã®å¹…ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
  blockHeight: 6.0,          // å„ãƒ–ãƒ­ãƒƒã‚¯ã®é«˜ã•ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
  
  // é–“éš”èª¿æ•´
  gapX: 43.61,                  // ãƒãƒ³ãƒ‰é–“ã®æ°´å¹³æ–¹å‘ã®é–“éš”
  gapY1: 3.1,                // å¥‡æ•°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã®å‚ç›´æ–¹å‘ã®é–“éš”
  gapY2: 6,                // å¶æ•°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã®å‚ç›´æ–¹å‘ã®é–“éš”
  
  // ã‚¹ãƒ©ãƒ³ãƒˆãƒ»å‚¾æ–œèª¿æ•´
  slantLR: 2.0,              // å„ãƒ–ãƒ­ãƒƒã‚¯ã®å·¦å³æ–¹å‘ã®å‚¾ã
  slopeTB: 5.0,              // å„ãƒ–ãƒ­ãƒƒã‚¯ã®ä¸Šä¸‹æ–¹å‘ã®å‚¾ã
  stackSlant: 3.35,           // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ç©ã¿é‡ã­æ™‚ã®æ°´å¹³æ–¹å‘ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆ
  
  // ä½ç½®èª¿æ•´
  offsetX: 186.6,              // ã‚­ãƒ£ãƒ³ãƒã‚¹å·¦ç«¯ã‹ã‚‰ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆ
  offsetY: 8.2,                // ã‚­ãƒ£ãƒ³ãƒã‚¹ä¸‹ç«¯ã‹ã‚‰ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆ
  
  // éŸ³å£°è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
  divisor: 2,              // éŸ³å£°ãƒ¬ãƒ™ãƒ«ã®æ„Ÿåº¦ï¼ˆå¤§ãã„ã»ã©æ•æ„Ÿï¼‰
  fallSpeed: 0.15,           // ãƒãƒ¼ãŒä¸‹ãŒã‚‹é€Ÿåº¦ï¼ˆ0.0ã€œ1.0ï¼‰
  fadeAlpha: 0,              // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã®é€æ˜åº¦ï¼ˆ0ã€œ255ã€0ã§ç„¡åŠ¹ï¼‰
    
  fftSize: 8192,             // FFTã‚µã‚¤ã‚ºï¼ˆå¤§ãã„ã»ã©å‘¨æ³¢æ•°åˆ†è§£èƒ½ãŒé«˜ã„: 2048, 4096, 8192, 16384ï¼‰
  smoothing: 0,            // ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆ0.0ã€œ1.0ã€å°ã•ã„ã»ã©åå¿œãŒé€Ÿã„ï¼‰
  minDecibels: -90,          // æœ€å°ãƒ‡ã‚·ãƒ™ãƒ«
  maxDecibels: -7,          // æœ€å¤§ãƒ‡ã‚·ãƒ™ãƒ«
  
  // ã‚¬ã‚¤ãƒ‰ç”»åƒè¨­å®š
  showGuide: true,          // ã‚¬ã‚¤ãƒ‰ç”»åƒã‚’è¡¨ç¤ºã™ã‚‹ã‹ï¼ˆtrue/falseï¼‰
  guideAlpha: 0.1,           // ã‚¬ã‚¤ãƒ‰ç”»åƒã®é€æ˜åº¦ï¼ˆ0.0ã€œ1.0ï¼‰
}

// è‰²è¨­å®šï¼ˆRGBå€¤ï¼‰
const COLORS = {
  // ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®è‰²ï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
  activeBottom: [0, 255, 200] as [number, number, number],  // ä¸‹éƒ¨ã®è‰²ï¼ˆã‚·ã‚¢ãƒ³ç³»ï¼‰
  activeTop: [50, 50, 255] as [number, number, number],     // ä¸Šéƒ¨ã®è‰²ï¼ˆé’ç³»ï¼‰
  
  // éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®è‰²ï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
  inactiveBottom: [0, 40, 30] as [number, number, number],  // ä¸‹éƒ¨ã®è‰²ï¼ˆæš—ã„ã‚·ã‚¢ãƒ³ç³»ï¼‰
  inactiveTop: [10, 10, 50] as [number, number, number],    // ä¸Šéƒ¨ã®è‰²ï¼ˆæš—ã„é’ç³»ï¼‰
}

// ============================================================================

export function SpectrumAnalyzer() {
  const [isPlaying, setIsPlaying] = useState(false)
  const [audioFile, setAudioFile] = useState<string | null>(null)
  
  const canvasRef = useRef<HTMLCanvasElement>(null)
  const audioRef = useRef<HTMLAudioElement>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const analyzerRef = useRef<AnalyserNode | null>(null)
  const sourceRef = useRef<MediaElementAudioSourceNode | null>(null)
  const animationRef = useRef<number | null>(null)
  const previousLevelsRef = useRef<number[]>(new Array(SPECTRUM_CONFIG.numBands).fill(0))
  const guideImageRef = useRef<HTMLImageElement | null>(null)
  const audioInitializedRef = useRef<boolean>(false)

  useEffect(() => {
    const img = new Image()
    img.crossOrigin = 'anonymous'
    img.src="/images/design-mode/guide.png"
    img.onload = () => {
      guideImageRef.current = img
    }
    
    return () => {
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current)
        animationRef.current = null
      }
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close().catch(() => {})
      }
      audioInitializedRef.current = false
      audioContextRef.current = null
      sourceRef.current = null
      analyzerRef.current = null
    }
  }, [])

  const initializeAudio = () => {
    if (!audioRef.current || audioInitializedRef.current) {
      return
    }

    try {
      const audioContext = new AudioContext()
      const analyzer = audioContext.createAnalyser()
      
      analyzer.fftSize = SPECTRUM_CONFIG.fftSize
      analyzer.smoothingTimeConstant = SPECTRUM_CONFIG.smoothing
      analyzer.minDecibels = SPECTRUM_CONFIG.minDecibels
      analyzer.maxDecibels = SPECTRUM_CONFIG.maxDecibels

      const source = audioContext.createMediaElementSource(audioRef.current)
      source.connect(analyzer)
      analyzer.connect(audioContext.destination)

      audioContextRef.current = audioContext
      analyzerRef.current = analyzer
      sourceRef.current = source
      audioInitializedRef.current = true

      console.log('[v0] Audio initialized with FFT size:', analyzer.fftSize)
    } catch (error) {
      console.error('Failed to initialize audio:', error)
    }
  }

  const getGradientColor = (
    colorStart: [number, number, number],
    colorEnd: [number, number, number],
    ratio: number
  ): string => {
    const r = Math.floor(colorStart[0] * (1 - ratio) + colorEnd[0] * ratio)
    const g = Math.floor(colorStart[1] * (1 - ratio) + colorEnd[1] * ratio)
    const b = Math.floor(colorStart[2] * (1 - ratio) + colorEnd[2] * ratio)
    return `rgb(${r}, ${g}, ${b})`
  }

  const drawDoubleSlantedPolygon = (
    ctx: CanvasRenderingContext2D,
    color: string,
    x: number,
    y: number,
    w: number,
    h: number,
    slantLR: number,
    slopeTB: number
  ) => {
    const p4 = { x, y }
    const p3 = { x: x + w, y: y - slopeTB }
    const p1 = { x: x + slantLR, y: y - h }
    const p2 = { x: x + w + slantLR, y: y - h - slopeTB }

    ctx.fillStyle = color
    ctx.beginPath()
    ctx.moveTo(p1.x, p1.y)
    ctx.lineTo(p2.x, p2.y)
    ctx.lineTo(p3.x, p3.y)
    ctx.lineTo(p4.x, p4.y)
    ctx.closePath()
    ctx.fill()
  }

  const getAudioLevels = (dataArray: Uint8Array): number[] => {
    const levels: number[] = []
    const totalBins = dataArray.length / 2
    
    // äººé–“ã®è´è¦šç‰¹æ€§ã«åˆã‚ã›ãŸå‘¨æ³¢æ•°åˆ†å¸ƒã‚’å®Ÿç¾
    const minFreq = 10 // æœ€å°å‘¨æ³¢æ•°ãƒ“ãƒ³ï¼ˆ0ã‚’é¿ã‘ã‚‹ï¼‰
    const maxFreq = totalBins
    
    // å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã§ãƒãƒ³ãƒ‰ã®å¢ƒç•Œã‚’è¨ˆç®—
    const logMin = Math.log(minFreq)
    const logMax = Math.log(maxFreq)
    const logStep = (logMax - logMin) / SPECTRUM_CONFIG.numBands

    for (let i = 0; i < SPECTRUM_CONFIG.numBands; i++) {
      // ç­‰æ¯”æ•°åˆ—ã§å„ãƒãƒ³ãƒ‰ã®é–‹å§‹ãƒ»çµ‚äº†ä½ç½®ã‚’æ±ºå®š
      const start = Math.floor(Math.exp(logMin + i * logStep))
      const end = Math.floor(Math.exp(logMin + (i + 1) * logStep))
      
      let sum = 0
      let count = 0
      for (let j = start; j < end && j < dataArray.length; j++) {
        sum += dataArray[j]
        count++
      }
      const magnitude = count > 0 ? sum / count : 0
      
      let val = magnitude / 255.0
      val = val * SPECTRUM_CONFIG.divisor
      val = Math.max(0.0, Math.min(val, 1.0))
      levels.push(val)
    }
    
    console.log('[v0] Audio levels sample:', levels.slice(0, 3).map(v => v.toFixed(3)))
    return levels
  }

  const drawSpectrum = () => {
    if (!canvasRef.current) return

    const canvas = canvasRef.current
    const ctx = canvas.getContext('2d', { alpha: false })
    if (!ctx) return

    if (SPECTRUM_CONFIG.fadeAlpha > 0) {
      ctx.fillStyle = `rgba(0, 0, 0, ${SPECTRUM_CONFIG.fadeAlpha / 255})`
      ctx.fillRect(0, 0, canvas.width, canvas.height)
    } else {
      ctx.fillStyle = '#000000'
      ctx.fillRect(0, 0, canvas.width, canvas.height)
    }

    if (SPECTRUM_CONFIG.showGuide && guideImageRef.current) {
      ctx.globalAlpha = SPECTRUM_CONFIG.guideAlpha
      ctx.drawImage(guideImageRef.current, 0, 0, canvas.width, canvas.height)
      ctx.globalAlpha = 1.0
    }

    let displayLevels: number[] = []

    if (analyzerRef.current && isPlaying) {
      const bufferLength = analyzerRef.current.frequencyBinCount
      const dataArray = new Uint8Array(bufferLength)
      analyzerRef.current.getByteFrequencyData(dataArray)

      const rawLevels = getAudioLevels(dataArray)
      
      for (let i = 0; i < SPECTRUM_CONFIG.numBands; i++) {
        const newVal = rawLevels[i]
        const prevVal = previousLevelsRef.current[i] || 0
        if (newVal > prevVal) {
          displayLevels[i] = newVal
        } else {
          displayLevels[i] = Math.max(0.0, prevVal - SPECTRUM_CONFIG.fallSpeed)
        }
      }
      previousLevelsRef.current = displayLevels
    } else {
      displayLevels = [...previousLevelsRef.current]
    }

    const startX = SPECTRUM_CONFIG.offsetX
    const startYBottom = canvas.height - SPECTRUM_CONFIG.offsetY

    for (let bandIdx = 0; bandIdx < SPECTRUM_CONFIG.numBands; bandIdx++) {
      const level = displayLevels[bandIdx] || 0
      const activeLevel = Math.floor(level * SPECTRUM_CONFIG.levelsPerBand)
      const activeSegments = activeLevel * 2
      
      const bandXBase = startX + bandIdx * (SPECTRUM_CONFIG.blockWidth + SPECTRUM_CONFIG.gapX)
      let currentYBottom = startYBottom

      for (let segIdx = 0; segIdx < SPECTRUM_CONFIG.segmentsPerBand; segIdx++) {
        const xOffset = segIdx * SPECTRUM_CONFIG.stackSlant
        const xDraw = bandXBase + xOffset
        const yDraw = currentYBottom

        const ratio = segIdx / SPECTRUM_CONFIG.segmentsPerBand

        let color: string
        if (segIdx < activeSegments) {
          color = getGradientColor(COLORS.activeBottom, COLORS.activeTop, ratio)
        } else {
          color = getGradientColor(COLORS.inactiveBottom, COLORS.inactiveTop, ratio)
        }

        drawDoubleSlantedPolygon(
          ctx,
          color,
          xDraw,
          yDraw,
          SPECTRUM_CONFIG.blockWidth,
          SPECTRUM_CONFIG.blockHeight,
          SPECTRUM_CONFIG.slantLR,
          SPECTRUM_CONFIG.slopeTB
        )

        const currentGapY = segIdx % 2 === 0 ? SPECTRUM_CONFIG.gapY1 : SPECTRUM_CONFIG.gapY2
        currentYBottom -= (SPECTRUM_CONFIG.blockHeight + currentGapY)
      }
    }

    animationRef.current = requestAnimationFrame(drawSpectrum)
  }

  useEffect(() => {
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current)
      animationRef.current = null
    }
    drawSpectrum()
  }, [isPlaying])

  const handlePlay = async () => {
    if (!audioRef.current) return

    if (!audioInitializedRef.current) {
      initializeAudio()
    }

    try {
      if (audioContextRef.current?.state === 'suspended') {
        await audioContextRef.current.resume()
      }

      await audioRef.current.play()
      setIsPlaying(true)
    } catch (error) {
      console.error('Failed to play audio:', error)
    }
  }

  const handlePause = () => {
    if (!audioRef.current) return
    audioRef.current.pause()
    setIsPlaying(false)
  }

  const handleFileUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0]
    if (file) {
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close().catch(() => {})
      }
      audioContextRef.current = null
      analyzerRef.current = null
      sourceRef.current = null
      audioInitializedRef.current = false
      
      const url = URL.createObjectURL(file)
      setAudioFile(url)
      setIsPlaying(false)
      previousLevelsRef.current = new Array(SPECTRUM_CONFIG.numBands).fill(0)
    }
  }

  return (
    <div className="w-full max-w-[1400px] space-y-4">
      <div className="bg-black border-2 border-white/20 rounded-lg overflow-hidden">
        <canvas
          ref={canvasRef}
          width={1400}
          height={400}
          className="w-full h-auto block"
        />
      </div>

      <div className="bg-zinc-900 border border-zinc-800 rounded-lg p-4">
        <div className="flex gap-3">
          <input
            type="file"
            accept="audio/*"
            onChange={handleFileUpload}
            className="hidden"
            id="audio-upload"
          />
          <label htmlFor="audio-upload">
            <Button variant="outline" size="sm" asChild>
              <span className="cursor-pointer flex items-center gap-2">
                <Upload className="h-4 w-4" />
                Upload Audio
              </span>
            </Button>
          </label>
          {audioFile && (
            <>
              {!isPlaying ? (
                <Button onClick={handlePlay} size="sm">
                  <Play className="h-4 w-4 mr-2" />
                  Play
                </Button>
              ) : (
                <Button onClick={handlePause} size="sm" variant="secondary">
                  <Pause className="h-4 w-4 mr-2" />
                  Pause
                </Button>
              )}
            </>
          )}
        </div>
      </div>

      {audioFile && (
        <audio ref={audioRef} src={audioFile} className="hidden" loop />
      )}
    </div>
  )
}
