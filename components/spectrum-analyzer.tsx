'use client'

import { useEffect, useRef, useState } from 'react'
import { Button } from '@/components/ui/button'
import { Play, Pause, Upload } from 'lucide-react'

// ============================================================================
// ğŸ¨ ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®èª¿æ•´ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
// ============================================================================

const SPECTRUM_CONFIG = {
  // ãƒãƒ³ãƒ‰è¨­å®š
  numBands: 17,              // ãƒãƒ³ãƒ‰ã®æ•°ï¼ˆå‘¨æ³¢æ•°å¸¯åŸŸã®æ•°ï¼‰
  segmentsPerBand: 26,       // å„ãƒãƒ³ãƒ‰ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°ï¼ˆç¸¦æ–¹å‘ã®ãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
  levelsPerBand: 13,         // éŸ³é‡ãƒ¬ãƒ™ãƒ«ã®æ®µéšæ•°ï¼ˆ2ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§1ãƒ¬ãƒ™ãƒ«ï¼‰
  
  // ãƒ–ãƒ­ãƒƒã‚¯ã®å¯¸æ³•
  blockWidth: 24.5,          // å„ãƒ–ãƒ­ãƒƒã‚¯ã®å¹…ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
  blockHeight: 6.0,          // å„ãƒ–ãƒ­ãƒƒã‚¯ã®é«˜ã•ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
  
  // é–“éš”èª¿æ•´
  gapX: 43.61,               // ãƒãƒ³ãƒ‰é–“ã®æ°´å¹³æ–¹å‘ã®é–“éš”
  gapY1: 3.1,                // å¥‡æ•°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã®å‚ç›´æ–¹å‘ã®é–“éš”
  gapY2: 6,                  // å¶æ•°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã®å‚ç›´æ–¹å‘ã®é–“éš”
  
  // ã‚¹ãƒ©ãƒ³ãƒˆãƒ»å‚¾æ–œèª¿æ•´
  slantLR: 2.0,              // å„ãƒ–ãƒ­ãƒƒã‚¯ã®å·¦å³æ–¹å‘ã®å‚¾ã
  slopeTB: 5.0,              // å„ãƒ–ãƒ­ãƒƒã‚¯ã®ä¸Šä¸‹æ–¹å‘ã®å‚¾ã
  stackSlant: 3.35,          // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ç©ã¿é‡ã­æ™‚ã®æ°´å¹³æ–¹å‘ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆ
  
  // ä½ç½®èª¿æ•´
  offsetX: 186.6,            // ã‚­ãƒ£ãƒ³ãƒã‚¹å·¦ç«¯ã‹ã‚‰ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆ
  offsetY: 8.2,              // ã‚­ãƒ£ãƒ³ãƒã‚¹ä¸‹ç«¯ã‹ã‚‰ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆ
  
  // éŸ³å£°è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
  divisor: 2,                // éŸ³å£°ãƒ¬ãƒ™ãƒ«ã®æ„Ÿåº¦ï¼ˆå¤§ãã„ã»ã©æ•æ„Ÿï¼‰
  fallSpeed: 0.01,           // ãƒãƒ¼ãŒä¸‹ãŒã‚‹é€Ÿåº¦ï¼ˆ0.0ã€œ1.0ï¼‰
  fadeAlpha: 0,              // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã®é€æ˜åº¦ï¼ˆ0ã€œ255ã€0ã§ç„¡åŠ¹ï¼‰
    
  fftSize: 8192,             // FFTã‚µã‚¤ã‚ºï¼ˆå¤§ãã„ã»ã©å‘¨æ³¢æ•°åˆ†è§£èƒ½ãŒé«˜ã„: 2048, 4096, 8192, 16384ï¼‰
  smoothing: 0.1,            // ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆ0.0ã€œ1.0ã€å°ã•ã„ã»ã©åå¿œãŒé€Ÿã„ï¼‰
  minDecibels: -90,          // æœ€å°ãƒ‡ã‚·ãƒ™ãƒ«
  maxDecibels: -10,           // æœ€å¤§ãƒ‡ã‚·ãƒ™ãƒ«
  
  peakHoldTime: 200,        // ãƒ”ãƒ¼ã‚¯ãŒæ®‹ã‚‹æ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰
  
  // ã‚¬ã‚¤ãƒ‰ç”»åƒè¨­å®š
  showGuide: true,           // ã‚¬ã‚¤ãƒ‰ç”»åƒã‚’è¡¨ç¤ºã™ã‚‹ã‹ï¼ˆtrue/falseï¼‰
  guideAlpha: 0.2,           // ã‚¬ã‚¤ãƒ‰ç”»åƒã®é€æ˜åº¦ï¼ˆ0.0ã€œ1.0ï¼‰
}

const SIDE_BAND_CONFIG = {
  // ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰è¨­å®š
  enabled: true,             // ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰ã‚’è¡¨ç¤ºã™ã‚‹ã‹ï¼ˆtrue/falseï¼‰
  segmentsPerBand: 26,       // å„ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°
  levelsPerBand: 13,         // éŸ³é‡ãƒ¬ãƒ™ãƒ«ã®æ®µéšæ•°ï¼ˆ2ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§1ãƒ¬ãƒ™ãƒ«ï¼‰
  
  // ãƒ–ãƒ­ãƒƒã‚¯ã®å¯¸æ³•
  blockWidth: 7.5,            // å„ãƒ–ãƒ­ãƒƒã‚¯ã®å¹…ï¼ˆãƒ¡ã‚¤ãƒ³ã‚ˆã‚Šå°ã•ã„ï¼‰
  blockHeight: 6.0,          // å„ãƒ–ãƒ­ãƒƒã‚¯ã®é«˜ã•ï¼ˆãƒ¡ã‚¤ãƒ³ã‚ˆã‚Šå°ã•ã„ï¼‰
  
  // é–“éš”èª¿æ•´
  gapY1: 3.1,                // å¥‡æ•°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã®å‚ç›´æ–¹å‘ã®é–“éš”
  gapY2: 6.0,                // å¶æ•°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã®å‚ç›´æ–¹å‘ã®é–“éš”
  
  // ã‚¹ãƒ©ãƒ³ãƒˆãƒ»å‚¾æ–œèª¿æ•´
  slantLR: 2.0,              // å„ãƒ–ãƒ­ãƒƒã‚¯ã®å·¦å³æ–¹å‘ã®å‚¾ã
  slopeTB: 2.0,              // å„ãƒ–ãƒ­ãƒƒã‚¯ã®ä¸Šä¸‹æ–¹å‘ã®å‚¾ã
  stackSlant: 3.35,           // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ç©ã¿é‡ã­æ™‚ã®æ°´å¹³æ–¹å‘ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆ
  
  // ä½ç½®èª¿æ•´ï¼ˆãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ã‹ã‚‰ã®ç›¸å¯¾ä½ç½®ï¼‰
  leftOffsetX: -11,          // å·¦ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰ã®Xæ–¹å‘ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆè² ã®å€¤ã§å·¦ã«é…ç½®ï¼‰
  rightOffsetX: 28,          // å³ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰ã®Xæ–¹å‘ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆæ­£ã®å€¤ã§å³ã«é…ç½®ï¼‰
  leftOffsetY: -2.5,         // å·¦ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰ã®Yæ–¹å‘ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ã®offsetYã‹ã‚‰ã®è¿½åŠ ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼‰
  rightOffsetY: 5,        // å³ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰ã®Yæ–¹å‘ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ã®offsetYã‹ã‚‰ã®è¿½åŠ ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼‰
  
  // é€£å‹•è¨­å®š
  linkToBand: 'same',        // ãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ã¨ã®é€£å‹•æ–¹æ³•: 'same'=åŒã˜ãƒãƒ³ãƒ‰ã¨é€£å‹•, 'adjacent'=éš£æ¥ãƒãƒ³ãƒ‰ã¨é€£å‹•
  levelMultiplier: 1,      // ãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ã®ãƒ¬ãƒ™ãƒ«ã«å¯¾ã™ã‚‹å€ç‡ï¼ˆ0.0ã€œ1.0ï¼‰
}

// è‰²è¨­å®šï¼ˆRGBå€¤ï¼‰
const COLORS = {
  // ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®è‰²ï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
  activeBottom: [0, 255, 200] as [number, number, number],  // ä¸‹éƒ¨ã®è‰²ï¼ˆã‚·ã‚¢ãƒ³ç³»ï¼‰
  activeTop: [50, 50, 255] as [number, number, number],     // ä¸Šéƒ¨ã®è‰²ï¼ˆé’ç³»ï¼‰
  
  // éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®è‰²ï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
  inactiveBottom: [0, 40, 30] as [number, number, number],  // ä¸‹éƒ¨ã®è‰²ï¼ˆæš—ã„ã‚·ã‚¢ãƒ³ç³»ï¼‰
  inactiveTop: [10, 10, 50] as [number, number, number],    // ä¸Šéƒ¨ã®è‰²ï¼ˆæš—ã„é’ç³»ï¼‰
  
  // ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰ç”¨ã®è‰²è¨­å®šã‚’è¿½åŠ 
  // ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰ç”¨ã®è‰²ï¼ˆãƒ¡ã‚¤ãƒ³ã¨åŒã˜ã§ã‚‚ã€åˆ¥ã®è‰²ã§ã‚‚èª¿æ•´å¯èƒ½ï¼‰
  sideActiveBottom: [0, 255, 200] as [number, number, number],
  sideActiveTop: [50, 50, 255] as [number, number, number],
  sideInactiveBottom: [0, 40, 30] as [number, number, number],
  sideInactiveTop: [10, 10, 50] as [number, number, number],
}

// ============================================================================

interface PeakHold {
  level: number
  timestamp: number
}

export function SpectrumAnalyzer() {
  const [isPlaying, setIsPlaying] = useState(false)
  const [audioFile, setAudioFile] = useState<string | null>(null)
  const [currentTime, setCurrentTime] = useState(0)
  const [duration, setDuration] = useState(0)
  
  const canvasRef = useRef<HTMLCanvasElement>(null)
  const audioRef = useRef<HTMLAudioElement>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const analyzerRef = useRef<AnalyserNode | null>(null)
  const sourceRef = useRef<MediaElementAudioSourceNode | null>(null)
  const animationRef = useRef<number | null>(null)
  const previousLevelsRef = useRef<number[]>(new Array(SPECTRUM_CONFIG.numBands).fill(0))
  
  // ãƒ”ãƒ¼ã‚¯ãƒ›ãƒ¼ãƒ«ãƒ‰ç”¨ã®Ref
  const peakHoldsRef = useRef<PeakHold[]>(new Array(SPECTRUM_CONFIG.numBands).fill(null).map(() => ({ level: 0, timestamp: 0 })))
  const sidePeakHoldsRef = useRef<PeakHold[]>(new Array(SPECTRUM_CONFIG.numBands).fill(null).map(() => ({ level: 0, timestamp: 0 })))
  
  const guideImageRef = useRef<HTMLImageElement | null>(null)
  const audioInitializedRef = useRef<boolean>(false)

  useEffect(() => {
    const img = new Image()
    img.crossOrigin = 'anonymous'
    const basePath = process.env.NODE_ENV === 'production' ? '/d919' : ''
    img.src=`${basePath}/images/design-mode/guide.png` // ãƒ‘ã‚¹ã¯ç’°å¢ƒã«åˆã‚ã›ã¦ç¢ºèªã—ã¦ãã ã•ã„
    img.onload = () => {
      guideImageRef.current = img
    }
    
    return () => {
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current)
        animationRef.current = null
      }
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close().catch(() => {})
      }
      audioInitializedRef.current = false
      audioContextRef.current = null
      sourceRef.current = null
      analyzerRef.current = null
    }
  }, [])

  const initializeAudio = () => {
    if (!audioRef.current || audioInitializedRef.current) {
      return
    }

    try {
      const audioContext = new AudioContext()
      const analyzer = audioContext.createAnalyser()
      
      analyzer.fftSize = SPECTRUM_CONFIG.fftSize
      analyzer.smoothingTimeConstant = SPECTRUM_CONFIG.smoothing
      analyzer.minDecibels = SPECTRUM_CONFIG.minDecibels
      analyzer.maxDecibels = SPECTRUM_CONFIG.maxDecibels

      const source = audioContext.createMediaElementSource(audioRef.current)
      source.connect(analyzer)
      analyzer.connect(audioContext.destination)

      audioContextRef.current = audioContext
      analyzerRef.current = analyzer
      sourceRef.current = source
      audioInitializedRef.current = true
    } catch (error) {
      console.error('Failed to initialize audio:', error)
    }
  }

  const getGradientColor = (
    colorStart: [number, number, number],
    colorEnd: [number, number, number],
    ratio: number
  ): string => {
    const r = Math.floor(colorStart[0] * (1 - ratio) + colorEnd[0] * ratio)
    const g = Math.floor(colorStart[1] * (1 - ratio) + colorEnd[1] * ratio)
    const b = Math.floor(colorStart[2] * (1 - ratio) + colorEnd[2] * ratio)
    return `rgb(${r}, ${g}, ${b})`
  }

  const drawDoubleSlantedPolygon = (
    ctx: CanvasRenderingContext2D,
    color: string,
    x: number,
    y: number,
    w: number,
    h: number,
    slantLR: number,
    slopeTB: number
  ) => {
    const p4 = { x, y }
    const p3 = { x: x + w, y: y - slopeTB }
    const p1 = { x: x + slantLR, y: y - h }
    const p2 = { x: x + w + slantLR, y: y - h - slopeTB }

    ctx.fillStyle = color
    ctx.beginPath()
    ctx.moveTo(p1.x, p1.y)
    ctx.lineTo(p2.x, p2.y)
    ctx.lineTo(p3.x, p3.y)
    ctx.lineTo(p4.x, p4.y)
    ctx.closePath()
    ctx.fill()
  }

  const getAudioLevels = (dataArray: Uint8Array): number[] => {
    const levels: number[] = []
    const totalBins = dataArray.length / 2
    
    const minFreq = 10
    const maxFreq = totalBins
    
    const logMin = Math.log(minFreq)
    const logMax = Math.log(maxFreq)
    const logStep = (logMax - logMin) / SPECTRUM_CONFIG.numBands

    for (let i = 0; i < SPECTRUM_CONFIG.numBands; i++) {
      const start = Math.floor(Math.exp(logMin + i * logStep))
      const end = Math.floor(Math.exp(logMin + (i + 1) * logStep))
      
      let sum = 0
      let count = 0
      for (let j = start; j < end && j < dataArray.length; j++) {
        sum += dataArray[j]
        count++
      }
      const magnitude = count > 0 ? sum / count : 0
      
      let val = magnitude / 255.0
      val = val * SPECTRUM_CONFIG.divisor
      val = Math.max(0.0, Math.min(val, 1.0))
      levels.push(val)
    }
    
    return levels
  }

  // ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰æç”»é–¢æ•°ï¼ˆè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã‚’é™¤å»ã—ã€æç”»ã®ã¿ã«å°‚å¿µï¼‰
  const drawSideBand = (
    ctx: CanvasRenderingContext2D,
    bandIdx: number,
    currentLevelRatio: number, // è¨ˆç®—æ¸ˆã¿ã®ãƒ¬ãƒ™ãƒ«æ¯”ç‡ã‚’å—ã‘å–ã‚‹
    peakHold: PeakHold,        // è¨ˆç®—æ¸ˆã¿ã®ãƒ”ãƒ¼ã‚¯æƒ…å ±ã‚’å—ã‘å–ã‚‹
    baseX: number,
    baseY: number,
    now: number
  ) => {
    if (!SIDE_BAND_CONFIG.enabled) return
    
    const activeLevel = Math.floor(currentLevelRatio * SIDE_BAND_CONFIG.levelsPerBand)
    const activeSegments = activeLevel * 2
    
    // ãƒ”ãƒ¼ã‚¯è¡¨ç¤ºåˆ¤å®š
    let peakLevel = 0
    let showPeak = false
    
    if (now - peakHold.timestamp < SPECTRUM_CONFIG.peakHoldTime) {
      peakLevel = Math.floor(peakHold.level * SIDE_BAND_CONFIG.levelsPerBand)
      showPeak = peakLevel > activeLevel
    }
    
    let currentYBottom = baseY

    for (let segIdx = 0; segIdx < SIDE_BAND_CONFIG.segmentsPerBand; segIdx++) {
      const xOffset = segIdx * SIDE_BAND_CONFIG.stackSlant
      const xDraw = baseX + xOffset
      const yDraw = currentYBottom

      const ratio = segIdx / SIDE_BAND_CONFIG.segmentsPerBand
      const currentSegLevel = Math.floor(segIdx / 2)

      let color: string
      const isPeakSegment = showPeak && currentSegLevel === peakLevel
      
      if (segIdx < activeSegments || isPeakSegment) {
        color = getGradientColor(COLORS.sideActiveBottom, COLORS.sideActiveTop, ratio)
      } else {
        color = getGradientColor(COLORS.sideInactiveBottom, COLORS.sideInactiveTop, ratio)
      }

      drawDoubleSlantedPolygon(
        ctx,
        color,
        xDraw,
        yDraw,
        SIDE_BAND_CONFIG.blockWidth,
        SIDE_BAND_CONFIG.blockHeight,
        SIDE_BAND_CONFIG.slantLR,
        SIDE_BAND_CONFIG.slopeTB
      )

      const currentGapY = segIdx % 2 === 0 ? SIDE_BAND_CONFIG.gapY1 : SIDE_BAND_CONFIG.gapY2
      currentYBottom -= (SIDE_BAND_CONFIG.blockHeight + currentGapY)
    }
  }

  const updatePeakHold = (
    currentLevel: number, 
    peakHold: PeakHold, 
    now: number, 
    configLevels: number
  ) => {
    // ãƒ”ãƒ¼ã‚¯ãƒ›ãƒ¼ãƒ«ãƒ‰ã®ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆè¦ä»¶ã«æº–æ‹ ï¼‰
    if (currentLevel > peakHold.level) {
      // ä¸Šæ˜‡æ™‚ï¼šãƒ”ãƒ¼ã‚¯æ›´æ–° & ã‚¿ã‚¤ãƒãƒ¼ãƒªã‚»ãƒƒãƒˆ
      peakHold.level = currentLevel
      peakHold.timestamp = now
    } else if (now - peakHold.timestamp >= SPECTRUM_CONFIG.peakHoldTime) {
      // æ™‚é–“åˆ‡ã‚Œæ™‚ï¼šç¾åœ¨å€¤ã«è¿½å¾“ï¼ˆãƒ›ãƒ¼ãƒ«ãƒ‰è§£é™¤ï¼‰
      // ã“ã“ã‚’ '0' ã«ã™ã‚‹ã¨å†ä¸Šæ˜‡ã¨åˆ¤å®šã•ã‚Œã¦ã—ã¾ã†ãŸã‚ 'currentLevel' ã«ã™ã‚‹
      peakHold.level = currentLevel
    }
    // æ™‚é–“å†…ï¼ˆä¸‹é™ä¸­ï¼‰ã¯ peakHold.level ã‚’ç¶­æŒ
  }

  const drawSpectrum = () => {
    if (!canvasRef.current) return

    const canvas = canvasRef.current
    const ctx = canvas.getContext('2d', { alpha: false })
    if (!ctx) return

    if (SPECTRUM_CONFIG.fadeAlpha > 0) {
      ctx.fillStyle = `rgba(0, 0, 0, ${SPECTRUM_CONFIG.fadeAlpha / 255})`
      ctx.fillRect(0, 0, canvas.width, canvas.height)
    } else {
      ctx.fillStyle = '#000000'
      ctx.fillRect(0, 0, canvas.width, canvas.height)
    }

    if (SPECTRUM_CONFIG.showGuide && guideImageRef.current) {
      ctx.globalAlpha = SPECTRUM_CONFIG.guideAlpha
      ctx.drawImage(guideImageRef.current, 0, 0, canvas.width, canvas.height)
      ctx.globalAlpha = 1.0
    }

    let displayLevels: number[] = []
    const now = performance.now()

    if (analyzerRef.current && isPlaying) {
      const bufferLength = analyzerRef.current.frequencyBinCount
      const dataArray = new Uint8Array(bufferLength)
      analyzerRef.current.getByteFrequencyData(dataArray)

      const rawLevels = getAudioLevels(dataArray)
      
      for (let i = 0; i < SPECTRUM_CONFIG.numBands; i++) {
        const newVal = rawLevels[i]
        const prevVal = previousLevelsRef.current[i] || 0
        if (newVal > prevVal) {
          displayLevels[i] = newVal
        } else {
          displayLevels[i] = Math.max(0.0, prevVal - SPECTRUM_CONFIG.fallSpeed)
        }
      }
      previousLevelsRef.current = displayLevels
    } else {
      displayLevels = [...previousLevelsRef.current]
    }

    const startX = SPECTRUM_CONFIG.offsetX
    const startYBottom = canvas.height - SPECTRUM_CONFIG.offsetY
    const sideLeftYBottom = canvas.height - SPECTRUM_CONFIG.offsetY - SIDE_BAND_CONFIG.leftOffsetY
    const sideRightYBottom = canvas.height - SPECTRUM_CONFIG.offsetY - SIDE_BAND_CONFIG.rightOffsetY

    for (let bandIdx = 0; bandIdx < SPECTRUM_CONFIG.numBands; bandIdx++) {
      // 1. ãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ã®ãƒ¬ãƒ™ãƒ«è¨ˆç®—
      const mainLevel = displayLevels[bandIdx] || 0
      
      // 2. ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰ã®ãƒ¬ãƒ™ãƒ«è¨ˆç®—
      const sideLevel = mainLevel * SIDE_BAND_CONFIG.levelMultiplier

      // 3. ãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ã®ãƒ”ãƒ¼ã‚¯æ›´æ–°
      updatePeakHold(mainLevel, peakHoldsRef.current[bandIdx], now, SPECTRUM_CONFIG.levelsPerBand)
      
      // 4. ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰ã®ãƒ”ãƒ¼ã‚¯æ›´æ–°ï¼ˆã“ã“ã§è¨ˆç®—ã‚’ä¸€å›ã ã‘è¡Œã†ï¼‰
      updatePeakHold(sideLevel, sidePeakHoldsRef.current[bandIdx], now, SIDE_BAND_CONFIG.levelsPerBand)

      const bandXBase = startX + bandIdx * (SPECTRUM_CONFIG.blockWidth + SPECTRUM_CONFIG.gapX)
      
      // 5. ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰ï¼ˆå·¦ï¼‰æç”»
      drawSideBand(
        ctx,
        bandIdx,
        sideLevel,
        sidePeakHoldsRef.current[bandIdx], // è¨ˆç®—æ¸ˆã¿ã®çŠ¶æ…‹ã‚’æ¸¡ã™
        bandXBase + SIDE_BAND_CONFIG.leftOffsetX,
        sideLeftYBottom,
        now
      )
      
      // 6. ãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰æç”»
      const activeLevel = Math.floor(mainLevel * SPECTRUM_CONFIG.levelsPerBand)
      const activeSegments = activeLevel * 2
      
      const mainPeakHold = peakHoldsRef.current[bandIdx]
      let peakLevel = 0
      let showPeak = false
      
      if (now - mainPeakHold.timestamp < SPECTRUM_CONFIG.peakHoldTime) {
        peakLevel = Math.floor(mainPeakHold.level * SPECTRUM_CONFIG.levelsPerBand)
        showPeak = peakLevel > activeLevel
      }

      let currentYBottom = startYBottom

      for (let segIdx = 0; segIdx < SPECTRUM_CONFIG.segmentsPerBand; segIdx++) {
        const xOffset = segIdx * SPECTRUM_CONFIG.stackSlant
        const xDraw = bandXBase + xOffset
        const yDraw = currentYBottom

        const ratio = segIdx / SPECTRUM_CONFIG.segmentsPerBand
        const currentSegLevel = Math.floor(segIdx / 2)

        let color: string
        const isPeakSegment = showPeak && currentSegLevel === peakLevel
        
        if (segIdx < activeSegments || isPeakSegment) {
          color = getGradientColor(COLORS.activeBottom, COLORS.activeTop, ratio)
        } else {
          color = getGradientColor(COLORS.inactiveBottom, COLORS.inactiveTop, ratio)
        }

        drawDoubleSlantedPolygon(
          ctx,
          color,
          xDraw,
          yDraw,
          SPECTRUM_CONFIG.blockWidth,
          SPECTRUM_CONFIG.blockHeight,
          SPECTRUM_CONFIG.slantLR,
          SPECTRUM_CONFIG.slopeTB
        )

        const currentGapY = segIdx % 2 === 0 ? SPECTRUM_CONFIG.gapY1 : SPECTRUM_CONFIG.gapY2
        currentYBottom -= (SPECTRUM_CONFIG.blockHeight + currentGapY)
      }
      
      // 7. ã‚µã‚¤ãƒ‰ãƒãƒ³ãƒ‰ï¼ˆå³ï¼‰æç”»
      drawSideBand(
        ctx,
        bandIdx,
        sideLevel,
        sidePeakHoldsRef.current[bandIdx], // è¨ˆç®—æ¸ˆã¿ã®çŠ¶æ…‹ã‚’æ¸¡ã™
        bandXBase + SIDE_BAND_CONFIG.rightOffsetX,
        sideRightYBottom,
        now
      )
    }

    animationRef.current = requestAnimationFrame(drawSpectrum)
  }

  useEffect(() => {
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current)
      animationRef.current = null
    }
    drawSpectrum()
  }, [isPlaying])

  useEffect(() => {
    const audio = audioRef.current
    if (!audio) return

    const updateTime = () => setCurrentTime(audio.currentTime)
    const updateDuration = () => setDuration(audio.duration)

    audio.addEventListener('timeupdate', updateTime)
    audio.addEventListener('loadedmetadata', updateDuration)
    audio.addEventListener('durationchange', updateDuration)

    return () => {
      audio.removeEventListener('timeupdate', updateTime)
      audio.removeEventListener('loadedmetadata', updateDuration)
      audio.removeEventListener('durationchange', updateDuration)
    }
  }, [audioFile])

  const handlePlay = async () => {
    if (!audioRef.current) return

    if (!audioInitializedRef.current) {
      initializeAudio()
    }

    try {
      if (audioContextRef.current?.state === 'suspended') {
        await audioContextRef.current.resume()
      }

      await audioRef.current.play()
      setIsPlaying(true)
    } catch (error) {
      console.error('Failed to play audio:', error)
    }
  }

  const handlePause = () => {
    if (!audioRef.current) return
    audioRef.current.pause()
    setIsPlaying(false)
  }

  const handleFileUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0]
    if (file) {
      if (audioRef.current) {
        audioRef.current.pause()
        audioRef.current.currentTime = 0
      }
      setIsPlaying(false)
      
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close().catch(() => {})
      }
      audioContextRef.current = null
      analyzerRef.current = null
      sourceRef.current = null
      audioInitializedRef.current = false
      
      if (audioFile) {
        URL.revokeObjectURL(audioFile)
      }
      
      const url = URL.createObjectURL(file)
      setAudioFile(url)
      previousLevelsRef.current = new Array(SPECTRUM_CONFIG.numBands).fill(0)
      setCurrentTime(0)
      setDuration(0)
      
      e.target.value = ''
    }
  }

  const handleSeek = (e: React.ChangeEvent<HTMLInputElement>) => {
    const time = parseFloat(e.target.value)
    if (audioRef.current) {
      audioRef.current.currentTime = time
      setCurrentTime(time)
    }
  }

  const formatTime = (seconds: number) => {
    if (!isFinite(seconds)) return '0:00'
    const mins = Math.floor(seconds / 60)
    const secs = Math.floor(seconds % 60)
    return `${mins}:${secs.toString().padStart(2, '0')}`
  }

  return (
    <div className="w-full max-w-[1400px] space-y-4">
      <div className="bg-black border-2 border-white/20 rounded-lg overflow-hidden">
        <canvas
          ref={canvasRef}
          width={1400}
          height={400}
          className="w-full h-auto block"
        />
      </div>

      <div className="bg-zinc-900/50 border border-zinc-700/50 rounded-lg p-6 backdrop-blur-sm">
        <div className="flex flex-col gap-4">
          <div className="flex items-center gap-3">
            <input
              type="file"
              accept="audio/*"
              onChange={handleFileUpload}
              className="hidden"
              id="audio-upload"
            />
            <label htmlFor="audio-upload">
              <Button 
                variant="outline" 
                size="sm" 
                asChild
                className="bg-zinc-800 border-zinc-600 hover:bg-zinc-700 hover:border-zinc-500 text-zinc-100"
              >
                <span className="cursor-pointer flex items-center gap-2">
                  <Upload className="h-4 w-4" />
                  Upload Audio
                </span>
              </Button>
            </label>
            
            <Button 
              onClick={handlePlay} 
              size="sm"
              disabled={!audioFile}
              className="bg-cyan-600 hover:bg-cyan-500 text-white disabled:opacity-30 disabled:cursor-not-allowed"
            >
              <Play className="h-4 w-4 mr-2" />
              Play
            </Button>
            
            <Button 
              onClick={handlePause} 
              size="sm"
              className="bg-zinc-700 hover:bg-zinc-600 text-white"
            >
              <Pause className="h-4 w-4 mr-2" />
              Pause
            </Button>
            
            <div className="text-sm text-zinc-400 font-mono ml-auto">
              {formatTime(currentTime)} / {formatTime(duration)}
            </div>
          </div>
          
          <div className="flex items-center gap-3">
            <input
              type="range"
              min="0"
              max={duration || 0}
              value={currentTime}
              onChange={handleSeek}
              disabled={!audioFile}
              className="flex-1 h-2 bg-zinc-800 rounded-lg appearance-none cursor-pointer disabled:opacity-30 disabled:cursor-not-allowed"
              style={{
                background: `linear-gradient(to right, rgb(8 145 178) 0%, rgb(8 145 178) ${(currentTime / duration) * 100}%, rgb(63 63 70) ${(currentTime / duration) * 100}%, rgb(63 63 70) 100%)`
              }}
            />
          </div>
        </div>
      </div>

      {audioFile && (
        <audio 
          key={audioFile}
          ref={audioRef}
          src={audioFile}
          className="hidden"
          loop 
        />
      )}
    </div>
  )
}